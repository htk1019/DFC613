## 4강 팩터투자기초 <a name = "factor"></a>

### 팩터 모델 수식

팩터 모델의 목표는 자산 가격을 움직이는 이유가 무엇인지를 설명하는 모델을 찾는 것입니다. 이 모델은 여러 요인(팩터)이 주식의 수익률에 영향을 미친다고 가정합니다. 이 요인은 시장 전체의 변동성, 개별 기업의 규모, 가치, 수익성 등과 같은 경제적, 금융적 특성이 될 수 있습니다.

그렇다면 첫번째 질문은 과연 어떤 특성이나 요인들이 주식의 평균 수익률에 정보를 잘 제공하는가하는가? 입니다. 이 질문에 답하면 여러 주식들의 수익률을 이해하는 데 도움이 되며 예측에 활용될 수 있습니다.

팩터 모델은 다음과 같은 형태로 표현됩니다. 팩터 모델은 주식의 수익률을 여러 팩터들의 가중합으로 설명합니다.

$$수익률=β_1​ ⋅팩터_1​ +β_2​ ⋅팩터_2​ +…+β_N​ ⋅팩터_N​ +오차항$$

$$r_{t,n}= \alpha_n+\sum_{k=1}^K\beta_{n,k}f_{t,k}+\epsilon_{t,n}$$

위 식에서 잔차에 대한 제약조건은 다음과 같습니다.

$$ \mathbf{E}[\epsilon_{t,n}]=0 $$

$$ cov(\epsilon_{t,n}, \epsilon_{t,m}) =0, \ \ \  for \ n \neq m $$

$$cov(f_n,\epsilon_n) =0 $$

제약조건의 각 부분을 설명하면 다음과 같습니다.

$\mathbf{E}[\epsilon_{t,n}]=0$: 이 식은 오차항의 기대값이 0임을 나타냅니다. 
즉, 오차항은 평균이 0인 무작위한 값입니다.

$cov(\epsilon_{t,n}, \epsilon_{t,m}) =0, \ \ \  for \ n \neq m$: 이 식은 다른 주식의 오차항끼리의 공분산이 0임을 나타냅니다. 즉, 다른 주식의 오차항은 서로 독립적입니다.

$cov(f_n,\epsilon_n) =0$: 이 식은 팩터와 오차항의 공분산이 0임을 나타냅니다. 즉, 팩터와 오차항은 서로 독립적입니다.

잔차의 평균은 0이고 서로 다른 주식들의 잔차의 상관관계는 0이며 잔차는 팩터가 설명하지 못하는 요인들로 잔차들 간의 상관관계역시 0이라는 가정 입니다. 

이런 유형의 모델중에서 가장 유명한 CAPM은 유일한 팩터로 시장 포트폴리오의 수익률을 사용합니다. 우리가 팩터를 이상현상이라고 부르는 이유는 그 결과가 CAPM과 모순되는 결과를 보여주기 때문입니다. 자산가격이상에 대한 경험적 증거는 Fama와 French의 논문 이후 많이 축적되어 왔습니다. 이 작업은 여러 메타 연구 예: Green, Hand, and Zhang ( 2013 ) , CR Harvey, Liu, Zhu ( 2016 ) 및 McLean 및 Pontiff ( 2016 ) 에 의해 증명되었습니다.

주식 수익률은 회귀 분석을 통해 모델링 됩니다. 이 모델링의 결과는 고정된 것으로 사용될 수도 있지만, 시간이 지나면서 재평가되어 새로운 모델로 발전할 수도 있습니다. 후자의 경우, 모델의 매개변수 추정치가 시간에 따라 변하거나, 최신 연구를 통해 매개변수 자체가 추가되거나 제거되면서 모델이 변합니다.

퀀트 모델링에는 이론적으로 회귀 분석이 필요하지만, 팩터별로 순위를 매기고 그 순위에 따라 포트폴리오를 구축하는 것도 퀀트 모델링의 한 형태입니다. 투자 전략에 중점을 둔 경우, 퀀트 펀드나 리스크 팩터를 직접 만들지 않고도 이런 순위 기반의 방식을 사용하여 투자 전략을 수립할 수 있습니다.

### 최근의 팩터 투자 연구 현황

팩터 투자에 대한 논의는 수십 년 동안 이어져 왔으며, 국내에서는 ETF의 부상과 함께 2010년대 이후 더욱 주목을 받았습니다. 금융 공학의 관점에서 보면, 실용적인 연구와 학문적 연구 사이의 상호 피드백은 매우 유익한 발전을 이끌어 왔습니다. 실무자들은 학문적 발견을 통해 새로운 아이디어를 얻으며, 연구자들은 실용적인 주제를 더 깊게 연구하게 되었습니다.

최근 연구자들은 팩터로 구성된 인덱스를 개발하고 그 설명력을 정량화하여 학문적 의미를 부여하는 데 주력하고 있습니다. 예를 들어, Krkoska와 Schenk-Hoppé (2019)는 군집 행동을 분석하여 팩터 투자의 중요성을 강조했습니다. 또한, Cong와 Xu (2019)는 ETF와 같은 복합 증권의 도입이 시장 변동성과 자산 간 상관 관계를 증가시켰다고 밝혔습니다.

시장 이상 현상을 발견하고 팩터로 식별하는 연구들은 종종 부분적으로만 좋은 결과를 강조하며, 긍정적인 결과에 대한 연구만 출판되는 경향이 있습니다. 이러한 편향 때문에 나중에 이러한 연구 결과들이 무효화되는 경우가 많습니다. 그럼에도 불구하고, 주목을 받기 위해 부분적으로만 좋은 결과를 강조하여 보고하려는 유혹은 여전히 존재합니다. 따라서 발굴된 팩터들 중 상당수는 발표 이후에 급격히 유효성이 떨어질 수 있습니다. 특히, 논문에서는 고려되지 않은 높은 거래비용이 발생하는 실전에서는 성과가 더욱 나빠질 수 있습니다. (예: 소형주 퀀트 투자 전략) 그러므로 연구 결과를 무조건적으로 믿지 말고, 직접 연구하고 수행하는 것이 진정한 퀀트 투자라고 할 수 있습니다.

보통 이상현상이 공개되면 다양한 투자자가 이를 기반으로 투자하여 가격을 높이고 알파의 크기는 작아지게 됩니다. McLean과 Pontiff ( 2016 ) 와 Shanaev와 Ghimire ( 2020 ) 는  미국에서 이런 현상이 두드러진다고 보고했습니다. 다만 국내에서나 신흥국 등에서는 발행된 후에도 효과가 지속하는 편이라고 언급했습니다.

금융 저널은 크게 두가지 종류가 있습니다. 첫번째는 학술지 입니다. 교수가 작성하고 독자는 주로 학자들을 대상으로 합니다. 내용은 길고 기술적인 내용이 많습니다. 유명한 저널로는 Journal of Finance, Review of Financial Studies, Journal of Financial Economics 등이 있습니다. 두번째는 좀 더 실무자들에게 가까운 유형입니다. 짧고 읽기 쉬우며 주로 금융 실무자들을 대상으로 합니다. 유명한 저널로는 Journal of Portfolio Management와 Financial Analysts journal 등이 있습니다.

다양한 논문들이나 책들이 팩터 투자나 스타일 배분이라는 주제에 관해 출간되었습니다.

* Ilmanen ( 2011 ) : 많은 자산군에 걸친 위험 프리미엄에 대한 통계치 조사
* Ang (2014): 자산관리자에게 필요한 팩터 투자에 대한 지식
* Bali, Engle, and Murray (2016): 각종 투자관련 신호의 횡단면 분석
* Jurczenko ( 2017 ) : 팩터 순도, 예측가능성, 선택과 비중, 팩터 타이밍

그밖에 Goyal ( 2012 ) , Cazalet and Roncalli ( 2014 ) , Baz et al. ( 2015 )  등도 읽어보길 추천합니다.

### **포트폴리오 정렬을 통한 팩터 찾기**

팩터를 찾는 절차는 Fama-French(1992)에서 사용된 절차를 기반으로 일반화되었습니다. 이 절차의 아이디어는 간단하며, 다음과 같은 순서로 진행됩니다.

1. 특정일에, 특정 기준(예: 시가총액, 장부 시가 비율, 유동비율)에 따라 기업들의 순위를 매깁니다.
2. 해당 기준의 크기에 따라 J개의 그룹으로 포트폴리오를 만듭니다. 이때 J는 보통 2, 3, 5, 10을 사용하며, 이를 분위수라고 합니다. 각 그룹에는 동일한 수의 주식이 포함됩니다.
3. 각 그룹 내의 주식들의 비중은 주로 동일 가중을 사용하거나 시가총액 가중을 사용합니다.
4. 각 그룹의 미래 수익률을 계산합니다. 이때 수익률의 기간은 보통 1개월 이상입니다.
이 과정을 샘플 시간이 끝날 때까지 반복합니다.

간단하게 말하면, 이 절차는 특정 기준에 따라 기업들을 나누고, 각 그룹의 수익률을 계산하여 어떤 팩터가 수익률에 영향을 미치는지 파악하는 것입니다. 

이 절차의 결과는 포트폴리오 수익률의 시계열 데이터입니다. 각 그룹 j의 수익률은 
${r^j}_t$로 표시됩니다. 시장 이상 현상의 존재여부는 J=1인 그룹과 J=J인 그룹의 평균 수익률 사이에 통계적으로 유의한 차이가 있는지 t-test를 통해 확인됩니다. 더 강력한 테스트 방법은 Cattaneo et al. (2020)에 설명되어 있으며, 이 방법은 수익이 분류 기준에 따라 일정한 방향으로 변하지 않아 두 극단 포트폴리오만으로는 이를 파악하기 어려운 문제가 발생하는데 이 방법은 그런 단점을 해결해줍니다.

하나의 기준에만 집중하지 않고, 여러 특성에 따라 자산을 다차원으로 그룹화할 수도 있습니다. 예를 들어, Fama-French는 시가 총액과 장부/시가 비율을 결합하여 분석합니다. 각 특성은 10개의 그룹으로 나뉘어 총 100개의 포트폴리오가 만들어집니다. 정렬 프로세스에 포함될 수 있는 특성의 수에는 제한이 없습니다. 일부 연구자들은 많은 수의 특성을 파악할 수 있는 다양한 복잡한 알고리즘을 연구하기도 합니다 (예: Feng, Polson, and Xu (2019) 및 Bryzgalova, Pelger, and Zhu (2019)).

간단히 말하면, 이 절차는 포트폴리오 수익률의 시계열 데이터를 생성하고, 이 데이터를 분석하여 시장 이상 현상을 확인하거나 여러 특성을 결합하여 다차원으로 자산을 그룹화하여 분석합니다.

터가 될만한 지표의 유효성은 위와 같은 방식으로 검토를 합니다. 포트폴리오는 지표의 크기나 공통값에 의해 구성되며 팩터수익률은 하나의 극단 포트폴리오에서 반대 극단 포트롤리오의 수익률을 뺀 전략의 수익률을 의미합니다. 

앞에서 살펴본 팩터들 (SMB, HML 등)에 대한 연구자료를 살펴보겠습니다.

* Size (SMB = Small minus Big) :  Banz ( 1981 ) , Fama와 French ( 1992 ) , Fama와 French ( 1993 ) , Van Dijk ( 2011 ) , Clifford Asness et al. ( 2018 ) 및 Astakhov, Havranek 및 Novak ( 2019 ) .
* Value(HML = High minus Low, 저PBR 포트 - 고PBR 포트) : Fama and French (1992), Fama and French (1993), C. S. Asness, Moskowitz, and Pedersen (2013). See Israel, Laursen, and Richardson (2020) and Roca (2021)
* Momentum(WML = Winners minus Losers) :  Jegadeesh and Titman (1993), Carhart (1997) and C. S. Asness, Moskowitz, and Pedersen (2013). Winners 는 지난 1년간 가장 높은 수익률을 기록한 자산입니다. (지난 달을 생략하는 경우도 있음)
* Profitability(RMW = robust minus weak profits) :  Fama and French (2015), Bouchaud et al. (2019). 대표적인 Profitability는 매출총이익률입니다.
* Investment (CMA = conservative minus aggressive): Fama and French (2015), Hou, Xue, and Zhang (2015). 투자는 총 자산의 증가율로 측정됩니다. 공격적인 기업은 자산의 큰 성장을 경험하는 기업으로 볼 수 있습니다.
* Low Risk (BAB = betting against beta) : Ang et al. (2006), Baker, Bradley, and Wurgler (2011), Frazzini and Pedersen (2014), Boloorforoosh et al. (2020), Baker, Hoeyer, and Wurgler (2020) and Cliff Asness et al. (2020). 변동성을 쓰는 경우도 있고 베타를 사용하는 경우도 있습니다. Risk가 낮은 포트를 매수하고 높은 포트를 매도하는 전략의 수익률입니다.

미국 주식 팩터에 대해 Kenneth French의 데이터 라이브러리에서 무료로 사용할 수 있습니다. (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) 

모든 팩터 값은 시간의 흐름에 따라 변하며, 기업의 뉴스 발표 등에 의해 변화합니다. 대부분의 팩터는 장기 투자 시 좋은 성과를 보여줍니다.

특정 팩터에 투자하는 투자자의 특성에 대한 주제는 매우 흥미롭습니다. 이 주제를 다루고 있는 몇 가지 레퍼런스가 있습니다. Betermier, Calvet, and Sodini (2017)에서는 가치 투자자의 특성을 평균 연령이 높고, 부자이며, 임금이 안정적이라고 설명합니다. 그러나 Cronqvist, Siegel, and Yu (2015)에서는 다른 의견을 제시합니다. 이 연구에 따르면, 가치 투자자의 특성은 유전과 생활 경험에 근거하고 있다고 합니다.

### 팩터 분석의 수식적 접근 : 회귀, 정렬 및 P-Value 이해하기 ###

$$\textbf{r} = a+b\textbf{x}+\textbf{e}$$

r은 벡터이고 모든 주식들의 수익률을 뜻합니다. x는 최근의 지표값들을 의미합니다. 우리는 b를 추정하는 것이 목표입니다. 추정된 $\hat{b}$값이 통계적으로 유의한 수준이라면 x는 수익률을 예측하는데 유용하다고 해석합니다. 다만 추정된 $\hat{b}$값은 과거 데이터를 기반으로 하므로, 미래에도 잘 작동할지는 별도로 확인해야 합니다.

통계테스트는 포트폴리오 정렬에도 사용됩니다. 두 개의 극단적인 포트폴리오가 매우 다른 평균 수익률을 산출할 것으로 가정합니다. 두 포트폴리오의 수익률은 $r^+_t$ 와 $r^-_t$로 표현 됩니다. 

가장 간단한 방법은 t-test입니다. $t=\sqrt{T}\frac{m_{r_+}-m_{r_-}}{\sigma_{r_+-r_-}}$, 여기서 T는 데이터의 갯수를 의미하고 $m_{r_\pm}$는 평균 수익률을 의미하며 $\sigma_{r_+-r_-}$는 두 그룹 수익률차이의 표준편차를 뜻합니다. 

이는 롱숏포트폴리오의 변동성을 뜻한다고 볼 수도 있습니다. 본 수치는 샤프비율과도 유사한 면이 있습니다. t값은 p-value로 변환됩니다. p-value는 가설이 주어졌을 때 데이터 샘플이 존재할 가능성입니다. 즉 우리가 알고자 하는 것은 데이터가 주어졌을 때 그 가설이 될 확률입니다.

우리는 데이터가 주어졌을 때 그 가설이 현실이 될 확률이 필요합니다. 

$$\text{p-value} = P[D|H]$$

$$\text{target prob} = P[H|D] = \frac{P[D|H]}{P[D]}\times P[H]$$

H는 가설을 의미하고 D는 데이터를 의미합니다. 그러므로 p-value값이 작으면 가설이 기각됩니다. 가설은 주로 "팩터가 의미가 없다." 가설이 기각되면 팩터가 의미가 있을 가능성이 있는 것으로 해석합니다.

발표된 많은 팩터들이 out-of-sample 테스트에서 탈락했다는 연구결과가  Linnainmaa and Roberts (2018) and Hou, Xue, and Zhang (2020)에 존재합니다.

### **Fama-Macbeth regressions** ###

Fama-Macbeth 회귀(Fama-Macbeth regressions)는 팩터 모델링과 관련된 자산의 수익률을 분석하기 위해 널리 사용되는 통계 방법입니다. Fama와 Macbeth가 1973년에 제안한 이 방법은 시계열과 교차 섹션 데이터를 모두 사용하여 자산 수익률과 팩터 간의 관계를 추정하는 데 유용합니다.

Fama-Macbeth 회귀는 다음 두 단계로 진행됩니다.

1. 각 시간 단위(예: 월별)에 대해 각 주식들의 수익률을 독립 변수(팩터)에 대한 회귀 분석을 수행하여 계수를 추정합니다. 이 단계에서 추정된 계수는 각 주식의 팩터에 대한 감도(베타)를 나타냅니다.

2. 각 시간 단위에서 추정된 베타를 종속 변수로 사용하여 회귀를 수행합니다. 이 단계에서 추정된 계수는 팩터의 위험 프리미엄을 나타냅니다.

Fama-Macbeth 회귀는 팩터의 위험 프리미엄을 추정하고, 팩터가 수익률에 얼마나 영향을 미치는지 평가하는 데 유용합니다. 
이 방법은 자산 수익률의 시계열과 교차 섹션 차원을 모두 고려하여 팩터 모델의 적합성을 평가합니다.

[1단계] 각 주식에 대해 K개의 팩터를 독립변수로 두고, N개의 주식의 수익률을 종속 변수로 하는 회귀 분석을 수행합니다.

$$R_{1,t} = \beta_1 + \beta_{1,F_1}F_{1,t} + \beta_{1,F_2}F_{2,t} + ... \beta_{1,
    F_k}F_{k,t} + \epsilon_{1,t}$$

$$R_{2,t} = \beta_2 + \beta_{2,F_1}F_{1,t} + \beta_{2,F_2}F_{2,t} + ... \beta_{2,F_k}F_{k,t} + \epsilon_{2,t}$$

$$.$$

$$.$$

$$R_{N,t} = \beta_N + \beta_{N,F_1}F_{1,t} + \beta_{N,F_2}F_{2,t} + ... \beta_{N,F_k}F_{k,t} + \epsilon_{N,t}$$

[2단계] 1단계 에서 구한 베타($\hat{\beta}$)를 독립변수로 넣고 
각 시점의 포트폴리오 수익률($R_{i,t}$, i=1,....n)을 종속변수로 하는 회귀분석을 수행합니다.

$$R_{i,1} = \lambda_{1,0} + \lambda_{1,1}\beta_{i,F_1} + \lambda_{1,2}\beta_{i,F_2} + ... \lambda_{1,K}\beta_{i,F_K} +\epsilon_{i,1}$$

$$R_{i,2} = \lambda_{2,0} + \lambda_{2,1}\beta_{i,F_1} + \lambda_{2,2}\beta_{i,F_2} + ... \lambda_{2,K}\beta_{i,F_K} + \epsilon_{i,2}$$

$$.$$

$$.$$

$$R_{i,T} = \lambda_{T,0} + \lambda_{T,1}\beta_{i,F_1} + \lambda_{T,2}\beta_{T,F_2} + ... \lambda_{T,K}\beta_{i,F_K} + \epsilon_{T,2}$$

1단계는 N개의 주식에 각각 시계열 회귀분석을 수행하는 것이고 
2단계는 T개의 시점 모든 주식에 대하여 회귀분석을 수행하는 것입니다. 

2단계의 결과로 나오는 회귀계수 행렬 $\hat{\lambda}_{T\times K}$를 시간축 t에 대해 평균을 취한 각 팩터의 계수값을 각 팩터에 대한 최종적인 회귀계수 추정값으로 사용합니다. 

여기서 $\hat{\lambda}_{t,k}$는 t 시점에서 팩터에 대한 리스크 프리미엄으로 해석됩니다.

k번째 팩터에 대한 프리미엄은 다음과 같습니다.

$$\lambda_k=\frac{1}{T}\sum_{t=1}^T\lambda_{t,k}$$

팩터가 의미가 있는지를 보는 t-test는 여기서도 수행이 되는데 t값은 다음과 같습니다.

$$t_k=\frac{\lambda_k}{\sigma_k/\sqrt{T}}$$

여기서 $\sigma_k$ 값은 $\lambda_{t,k}$ 의 표준편차 입니다.

### 알파($\alpha$)의 개념

주식 퀀트 포트폴리오는 크게 두 가지 유형으로 나뉩니다. 첫 번째 유형은 벤치마크나 시장 지수를 능가하는 성과를 추구하는 것이며, 두 번째 유형은 시장을 잘 따라가도록 하는 것입니다. 시장 지수를 초과하는 수익률을 달성하기 위한 포트폴리오를 알파 추구 포트폴리오라고 부릅니다. 알파를 추구하지 않는 펀드를 인덱스 펀드라고 부릅니다.

이때 알파라는 용어가 중요합니다. 투자자들이 펀드를 소개하거나 운용 보고서에서 "알파를 추구한다"라고 말하는데, 알파는 자주 오해되는 개념 중 하나입니다. 이 용어를 자세히 정의하는 이유는 퀀트 운용에 필요한 사고를 정립하는 데 도움이 되기 때문입니다.

알파는 펀드 수익률에서 시장 수익률을 뺀 것이 아닙니다. 이렇게 생각하는 것은 오해입니다. 그 이유는 위험을 고려하지 않았기 때문입니다. 알파는 포트폴리오의 수익률이 시장 수익률과 비교해서 얼마나 더 나은지를 나타내는 것으로, 위험을 고려하여 계산됩니다. 위험을 감안한 수익률이 더 높을수록 좋은 알파를 가진 것으로 간주됩니다.


알파는 투자자들이 자주 사용하는 단어로, 투자 세계에서 "초과성과"라는 의미로 일반적으로 사용됩니다. 예를 들어, "포트폴리오 매니저가 '꾸준한 플러스 알파'를 추구한다"는 말을 듣게 될 것입니다. 이 말은 포트폴리오가 KOSPI나 NASDAQ과 같은 비교 지수보다 높은 수익률을 달성하려고 한다는 의미입니다. 그러나 이 경우의 알파는 단순히 지수 대비 초과 성과가 아닙니다. 알파는 위험을 고려한 초과 성과를 의미합니다.

알파를 이해하려면 포트폴리오 수익률과 벤치마크 수익률을 비교하는 것 외에도 위험 요소를 고려해야 합니다. 즉, 알파는 단순히 초과 수익률이 아니라, 위험을 고려한 초과 수익률을 의미합니다. 알파가 증가했다는 것은 상대적으로 낮은 위험을 가지고도 포트폴리오의 수익률이 좋았다는 것을 의미합니다.

알파를 측정할 때 기준이 되는 지수를 벤치마크라고 합니다. 벤치마크는 다양한 자산을 사용할 수 있습니다. 대표적으로 KOSPI200과 같은 시장 지수를 사용할 수 있으며, CAPM이나 파마-프렌치 3팩터 모델의 수익률도 사용할 수 있습니다. 또한 회사 내부의 리스크 팩터 모델을 사용할 수도 있습니다

**벤치마크 알파**(benchmark $\alpha$)

포트폴리오 수익률을 $r_P$라 하고 벤치마크의 수익률을 $r_B$라고 하면 벤치마크 알파는 다음과 같은 방정식으로 표현됩니다.
$$r_P = \alpha + \beta r_B + \epsilon$$

이 방정식에서 $\beta r_B$는 벤치마크와 관련있는 기대수익률 입니다. 나머지 $\alpha + \epsilon$는 잔차 혹은 잔여 수익률이라고 표현합니다. 포트폴리오 매니저의 목표는 위험 조정 수익률을 높이는 것이기 때문에 잔여 수익률이 중요합니다.

벤치마크 수익률이 플러스인 경우, 포트폴리오가 벤치마크 노출을 증가시키는 행위만 해도 더 높은 수익을 창출할 수 있습니다. 그러나 이는 매니저가 창출한 부가가치로 인정받지 못합니다. 원래 내재된 위험에 대한 보상을 받은 것일 뿐이지 매니저가 추가로 뭔가를 잘해서 기록한 수익률이 아니기 때문입니다. 그렇다면 잔여 수익률이 중요하다는 말이 됩니다. 벤치마크에 대한 비중 증가와 무관한 매니저 자신의 능력으로 만들어낸 것이 잔여 수익률이기 때문입니다.

여기서 $\alpha$는 잔여 수익률의 기대값이며 ϵ은 기대되는 평균 수익률과의 차이를 의미합니다. 랜덤하게 발생하는  ϵ의 기대값은 0이므로 $\alpha$ 이는 기준치를 초과한 진정한 초과수익률을 의미하기 때문입니다. 우리는 이를 위험 조정 초과수익을 달성했다고도 표현합니다.
​
예를 들어, 어떤 펀드 매니저의 포트폴리오가 바이오 주식과 IT 성장주로만 구성되어 있습니다. 최근 6개월간 이 펀드의 성과가 50%였는데 해당 기간동안 KOSPI200 지수는 30%인 경우 알파는 20%(=50%-30%)라고 오해하기 쉽습니다. 사실은 바이오와 IT는 시장이 오를 때 보통 2배가 오르고 떨어질 때도 2배가 떨어진다는 사실을 안다면 이 펀드의 최근 6개월 동안의 알파는 -10%가 됩니다. 바이오와 IT에만 투자 했을 때 부담한 위험을 감안 했을 때 기대수익률은 60%가 되어야 하는데 50%밖에 달성하지 못했기 때문입니다. 이때는 매니저가 특별히 추가로 잘한 것은 없고 바이오와 IT가 좋았기 때문에 높은 수익률이 난 것이라고 평가합니다.

알파의 개념에 대한 대략적인 감을 잡았다면 여러 종류의 알파를 한번 훑어 봅시다.
개념만 이해되면 충분합니다.

**CAPM $\alpha$**

포트폴리오 수익률 $r_p$가 주어지고 시장 수익률 $r_M$이 주어진 경우 포트폴리오의 수익률은 다음과 같은 형식일 것으로 추정합니다.

$$r_p = \alpha + \beta r_M + \epsilon$$

$\beta r_M$는 시장수익률과 관련된 포트폴리오의 기대수익률 입니다.
나머지인 $\alpha + \epsilon$ 가 알파와 오차의 합인 잔여 수익률 입니다. 여기서 시장을 S&P500같은 주식 인덱스라고 하면 벤치마크 알파와 CAPM 알파는 같은 알파입니다. 

CAPM 알파는 CAPM 이론을 기반으로 합니다. CAPM 이론은 주식의 기대 수익률이 시장에 대한 민감도(베타)로만 결정되어야 한다고 주장합니다. 즉, 주식의 수익률은 시장 수익률과의 상관성에 따라 결정된다고 말합니다.

CAPM 모델에 따르면, 알파(포트폴리오의 성과와 벤치마크 성과의 차이)의 기대값은 0이 되어야 합니다. 이는 주식의 수익률이 오직 시장 수익률과의 상관성에 따라서만 결정된다는 것이 CAPM의 주장이기 때문입니다.
그러나 실제 현실에서는 포트폴리오의 성과가 다양한 요인에 의해 영향을 받습니다. 
이로 인해 CAPM은 기대 수익률의 산출이 아닌, 포트폴리오의 실제 성과를 평가하는 데 주로 사용하게 되었습니다.

**멀티팩터 $\alpha$**

이 버전의 알파는 주식 수익률에 영향을 미치는 요인이 여러개가 있다고 가정합니다. 
$$r_p = \alpha + \beta_1 f_1 + \beta_2 f_2 + ...... + \beta_k f_k + \epsilon$$

이 모델에서 α는 멀티팩터 알파라고 하며 모델이 평가한 위험을 조정한 이후의 초과 수익을 측정하는데 사용합니다. 벤치마크 알파나 CAPM알파는 멀티팩터 알파들 중에서 팩터를 시장수익률 하나만 사용한 케이스 입니다. 그러므로 멀티팩터 알파가 가장 범주가 넓습니다. 팩터가 하나이고 그것이 벤치마크이면 멀티팩터 알파는 벤치마크 알파와 동일합니다.

실무적인 관점에서 봤을 때 벤치마크 설정을 잘못하거나 의도적으로 조작하면 포트폴리오의 성과가 더 좋아 보일 수 있습니다. 예를 들면 특정 섹터 주식만을 투자하는 펀드의 벤치마크로 시장지수를 사용한 다음 해당 섹터 주식들의 수익률인 높은 구간을 기준으로 알파를 측정하는 경우가 있겠습니다.
특정 섹터만 투자하는 펀드가 최근 3년 수익률이 시장 대비 3배가 나왔다고 알파를 창출했다고 보기는 어렵습니다. 비교 대상은 선택한 섹터 관련 지수여야 정당한 분석인 것입니다.

멀티팩터 알파를 수식으로 보면 다음과 같습니다.

$$ \alpha^B = E(\alpha + \beta_1 f_1 + \beta_2 f_2 + ..... + \beta_k f_k)$$

재정거래가격이론(Arbitrage Pricing Theory, APT)을 기반으로 한 설명에 따르면, 벤치마크 알파가 플러스여도 이 알파에는 다른 요인의 효과가 포함되어 있을 가능성이 존재합니다. 알파는 팩터의 노출도와 관련이 있을 수 있습니다. 예를 들어, 최근 모멘텀 주식들의 성과가 좋았다면, 모멘텀 노출도가 높은 펀드의 수익률이 좋을 것입니다. 하지만 이를 단순히 그냥 시장 수익률과 비교하면 알파가 창출된 것처럼 보입니다만 모멘텀 팩터와 시장 수익률을 함께 사용하면 알파는 사라집니다.

**Ex-Ante and Ex-Post $\alpha$**

어떤 α를 사용하던 예상되는 값과 실현되는 값 사이에는 차이가 반드시 존재합니다. ex-ante α는 사전에 예상되는 α이고 ex-post α는 과거 수익률로 계산한 이미 실현된 α 입니다. 보통 ex-ante α는 퀀트 포트폴리오 매니저가 포트폴리오룰 구성할 때 사용합니다. 예상되는 기대수익률과 위험 및 운용 제약조건을 가지고 포트폴리오를 구축할 때 목적식은 가장 높은 α를 달성하도록 만드는게 보통입니다. 일단 포트폴리오가 일정 기간 이상 운용되고나면, ex-post α를 계산할 수 있습니다. 이는 포트폴리오의 위험 조정 수익률이 실제 기대에 부합했는지 여부를 확인해줍니다.(매니저의 보너스는 ex-post α가 결정함) **뛰어난 매니저는 사실 ex-ante α와 ex-post α의 상관관계를 높게 가져가는 매니저입니다.** 무조건 수익률이 예상치보다 높다고 좋은 것은 아니라는 의미입니다. 둘의 차이가 크다고 하는 것은 높은 수익률이 매니저의 분석력이 아닌 운에 의해 결정 되었다는 의미이기 때문입니다.

**Ex-Ante and Ex-Post Information Ratio**

α라는 개념은 그 자체로 포트폴리오의 초과 수익률을 측정하는 아주 좋은 척도이지만 잔여 위험에 대한 개념을 추가하여 α를 조정하는 또 다른 좋은 평가지표가 있습니다. 이를 정보 비율(Information Ratio)이라고 합니다. 정보비율도 α와 마찬가지로 Ex-Ante 와 Ex-Post 가 있습니다. 정보비율의 공식은 다음과 같습니다.

$$IR = \frac{\alpha^B}{\omega}$$

분모는 벤치마크 대비 알파, 분자는 잔여 수익률로 계산한 표준편차 입니다.
정보비율은 한 단위의 잔여 위험 증가당 발생하는 알파를 의미합니다. 정보비율이 높을수록 포트폴리오는 잘 운용되고 있다고 볼 수 있습니다.

### **팩터 모델링에서 유의할 점** ###

데이터마이닝

퀀트 모델링에서 큰 과제 중 하나는 데이터 마이닝 문제 혹은 오버피팅 문제를 피하는 것입니다. 데이터 마이닝적 접근은 이론과 상식에 근거한 퀀트 모델을 개발하는데 방해 요소입니다. 물론 100% 피할수는 없기 때문에 잘 다뤄야 합니다.

데이터 마이닝(data mining)은 주식 수익과 상당한 상관관계가 있는 것처럼 보이지만 사실 의미가 없는 모델이나 소수의 팩터를 사용하게 합니다. 예를 들어 주식 수익률을 설명할 수 있는 99개의 잠재적 팩터 f1, f99가 있다고 가정해보겠습니다. 만약 이러한 팩터 값과 100개월 동안 주식 수익률의 관계를 알기위해 99개 팩터와 주식 수익률을 회귀시키면 어떻게 될꺼요? 아마 이 경우 회귀 분석에는 오류가 없으므로 회귀 분석의 적합도(R2)는 100%가 됩니다. 모델이 100% 과거 100개월 주식의 수익률을 설명한 것입니다. 그러나 사실 100%의 R2는 회귀분석에 너무 많은 변수를 포함시켜서 나온 결론입니다. 이 회귀 분석에서는 모형이 유효한지 여부에 대한 통계적 추론을 할 수 없습니다. 랜덤 수 생성기를 사용하여 100개월 동안 요인 값을 구성했더라도 회귀 분석에서는 R2가 정확히 100%가 되도록 계수를 할당했을 것입니다. 실제로 100개의 관측치와 99개 이상의 설명 변수가 있는 경우 R2는 항상 100%가 됩니다. 이것이 극단적 유형의 데이터 마이닝으로 모델을 찾는 방법입니다. 그러므로 R2가 높다고 해서 잘 설계된 모델은 아닙니다. 이러한 회귀의 결과는 어떤 의미에서 조작된 것에 더 가깝습니다.

오버피팅 말고도 데이터 마이닝 문제는 존재합니다. 1970년대에 시카고 대학의 경영대학원의 한 MBA 학생이 주식의 크기(즉, 시가총액)가 주식의 수익률을 설명한다는 것을 발견했었습니다. 이 학생인 연구자가 유효한 통계적 방법을 통해 이러한 결론을 내렸다고 가정해보겠습니다. 우리는 Size Factor로 명명된 이 현상이 이후 수백 명의 학계와 실무자들의 연구자료에 인용되고 활용 되었음을 압니다. 이렇게 되면 시가총액에 대한 결론에 반하는 연구는 잘 받아들여지지 않게 됩니다. 이는 연구자 커뮤니티 전체가 데이터 스누핑이라고 불리는 일종의 집단 데이터 마이닝을 하고 있는 것과 같습니다. 많은 사람들이 이미 검정하기 위해 사용한 것과 동일한 데이터로 요인을 검정할 때, 우리의 결론은 과거의 결론에 의해 영향을 받을 수 있습니다. 철저하게 객관적으로 보이는 모델링을 한 것처럼 보여도 기존 연구에 반하는 결과가 나오면 데이터 셋을 바꿔보거나 여러 가정을 집어넣어 기존에 널리 받아들여지는 연구와 일치하게 바꾸는 현상이 나타나기도 하는 것입니다. 이것 또한 데이터 마이닝의 한 종류입니다.

아무리 신중하게 연구해도 데이터 마이닝 문제를 피하기는 쉽지 않습니다. 현재까지 알려진  그나마 의미있는 접근법은 기술적인 분석 방법에 건전하고 상식적인 경제 이론적 접근법을 섞어 사용하는 것입니다. 과거 데이터에 전부 의존하기 보다는 결론을 보고 한번 더 이 요인과 주가의 관계를 다른 투자자들이 이용하지 않았거나 놓쳤던 이유에 대한 진지한 질문과 대답을 도출하는 과정이 있어야 합니다. 이런 과정을 거친 퀀트 전략이어야 향후에도 잘 작동할 것으로 기대할 수 있습니다.

투자전략의 범용성

과거 자료를 기반으로 예측을 한다는 것은 역사가 일부 반복된다는 가정으로 시작합니다.불행하게도, 시장의 끊임없는 흐름은 종종 우리가 계속될 것으로 기대할 수 있는 역사적 패턴을 바꾸기도 합니다. CEO, 직원, 제품, 시장 상황, 정뷰 규제도 계속 뀌며 기업이 바뀌면서 주식의 속성도 바뀌는 경우가 많습니다. 또한 국가 단위로 어떤 전략이 미국에서는 잘되는데 한국에서는 안되거나 일본에서만 잘 되는 전략이 개발되는 경우도 있습니다. 그렇기 때문에 개발된 투자전략은 다양한 기간, 다양한 국가 및 산업에 적용해보고 그 유용성을 파악해야 합니다. 만약 특정 산업에서 특히 잘 되는 투자전략이 발견되면 그 산업에서 유독 잘되는 이유를 찾아보고 같은 산업인데도 특정 국가는 잘 작동 되지 않았다면 납득할만한 이유를 찾아야합니다. 만약 한국의 특정 산업에서 잘 작동한 전략이 미국에서는 잘 안되었다면 그 전략은 한국에서도 향후 잘 작동하지 않을 확률이 높습니다.

올바른 모델을 선택하는 방법

경제이론적 설명이 가능한지 여부 : 퀀트 모델은 경제 이론적 관점에서 설명이 가능해야 한다고 말합니다. 경제이론은 높은 기대수익이 추가적인 위험을 감수하는 대가로만 정당화 할수 있다고 설명합니다. 파마 프렌치에서 사용하는 소형주와 가치주는 특별히 더 좋은점이 있어서 수익이 나는 것이 아니라 소형주와 가치주를 편입하는 것이 포트폴리오의 위험을 증가시키기 때문에 그 위험에  대한 대가로 추가적인 수익을 창출한다는 설명을 덧붙입니다. 만약 이것이 납득이 가지 않는 다른 연구자들은 기업의 규모와 가치팩터를 사용하기 보다 본질가치에 가깝다고 여기는 다른 팩터를 사용합니다. 이런 팩터를 연구자료로 발간하거나 실전에서 사용할 떄는 단순히 과거 성과가 좋거나 설명을 잘한다는 이유로 모델을 선택하는 것이 아닌 그 매커니즘에 대한 경제학적 설명을 덧붙여가 가치가 있다고 평가받습니다.

다양한 종류의 지표를 조합할 수 있어야 함 :  PER, PBR같은 재무와 가격관련 지표, 기업규모, 모멘텀, 기술적지표, 거래량 등 다양한 기업관련 지표와 함께 GDP, 인플레이션 같은 지표들도 함께 조합해서 사용하면 좋습니다.투자전략을 연구하는 사람이라면 가용한 모든 종류의 지표들을 조합해볼 필요가 있습니다.

직관적으로 이해가 되는가? : 최고의 모델은 상식에 기반한 모델입니다. 모델의 사용자는 숫자가 아닌 문장으로 설명해도 이해가 되고 납득이 되는 모델을 사용하는 것이 바람직 합니다. 그렇지 않으면 뛰어난 모델이라도 사용자가 잘못 사용할 여지가 있습니다.

## 마치며
이제 본격적으로 실무에서 사용하는 퀀트 주식 포트폴리오 운용에 필요한 모델을 살펴보도록 하겠습니다.


## @1. 부록 

학술 문헌에서 논의된 데이터 마이닝에 대한 두 가지 접근 방식을 간략하게 설명하겠습니다. 이 접근 방식은 데이터 마이닝에서 발생할 수 있는 위험을 완전히 제거하지는 못하지만, 이러한 위험을 이해하고 관리하는 데 도움이 될 수 있습니다.

#### 1. 본페로니 유형 조정(Bonferroni correction)

본페로니 조정은 여러 개의 통계적 가설 검정을 동시에 수행할 때 사용되는 방법입니다. 이 조정은 각 가설 검정의 유의 수준을 조정하여 가짜 양성 결과의 확률을 줄입니다.

본페로니 조정에서 t-검정의 임계값을 결정하는 방법은 다음과 같습니다:

- M을 테스트된 팩터의 수라고 하고, α를 선택한 유의 수준(예: 0.05)이라고 합니다.
- 본페로니 조정의 임계 p값(p*)은 α/M으로 계산됩니다. 여기서 α는 원래의 유의 수준이고, M은 테스트된 팩터의 수입니다.
- 이렇게 계산한 임계 p값(p*)를 사용하여 임계 t값(t*)를 역산합니다. 

위의 과정을 통해, 본페로니 조정을 사용하여 t-검정의 임계값을 구할 수 있습니다. 이를 통해 여러 개의 가설 검정을 수행하면서도 가짜 양성 결과를 줄일 수 있습니다.

본페로니 또는 홈 조정법을 구현할 때 가장 어려운 부 분은 테스트할 팩터의 수를 결정하는 것입니다. 일부 계산에 따르면 2012년 까지 약 313개 논문의 316개의 팩터가 존재합니다. 현재는 400개가 넘습니다. 그렇다면 본페로니 임계 t-값은 3.78입니다. 이정도를 벗어나야 유의미하다고 볼 수 있습니다.

#### 2. 베이지안 조정

베이지안 통계학은 주관적인 확률을 사용하여 가설 검정을 수행합니다. 이러한 접근 방식은 데이터 마이닝과 관련된 문제를 완화하는 데 도움이 될 수 있습니다.

- 베이지안 접근 방식은 사전 확률, 가능성, 사후 확률의 개념을 사용합니다.
- 사전 확률은 데이터를 보기 전에 가설이 참일 확률입니다.
- 가능성은 데이터가 주어졌을 때 가설이 참일 확률입니다.
- 사후 확률은 데이터를 본 후에 가설이 참일 확률입니다.
- 베이지안 통계에서 사후 확률은 사전 확률과 가능성의 곱으로 계산됩니다.
- 사후 확률 비율(오즈비) 은 귀무 가설에 대한 사후 확률을 대안 가설에 대한 사후 확률로 나눈 값입니다.
- 이 비율은 사전 확률 비율과 가능성 비율의 곱으로도 계산됩니다.
- 가능성 비율은 특정 가설을 참조하지 않고 계산됩니다.

수식으로 표현하면 다음과 같습니다.

P(H∣D)=  P(D) P(D∣H)⋅P(H)

​P(H∣D)는 데이터 D가 주어졌을 때 가설 H가 참일 사후 확률입니다.
P(D∣H)는 가설H가 참일 때 데이터 D가 관측될 가능성입니다.
P(H)는 가설 H가 참일 사전 확률입니다
P(D)는 데이터 D가 관측될 마지노트 확률입니다.

사후확률 비율 = $\frac{P(H_0|D)}{P(H_1|D)}$

$P(H_0)와 P(H_1)$는 각각 귀무 가설과 대안 가설의 사전 확률입니다

$P(D|H_0)와 P(D|H_1)$는 각각 귀무 가설과 대안 가설이 참일 때 데이터 D가 관측될 가능성입니다.

데이터를 본 후에 가설이 참일 확률을 계산하고, 가설 검정을 수행할 수 있습니다.
